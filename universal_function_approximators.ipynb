{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 align=\"center\" style=\"color:green;font-size: 3em;\" >Neural Networks</h1>\n<h1 align=\"center\" style=\"color:green;font-size: 2em;\" >Universal Function Approximators</h1>\n\n## An exercise on the basics of neural network:\n\n**1. Data Preprocessing.**\n\n**2. Perceptron (Linear Regression).**\n\n**3. Hyperparameters (Optimizer and Loss Function).**\n\n**4. Training.**\n\n**5. Exploring Loss Function Landscape.**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing\n\n## Create our data, convert to tensors, store in a pytorch dataset, use a loader to shuffle and serve the data in batches ","metadata":{}},{"cell_type":"code","source":"# Define the input data\nsize = np.array([2104, 1600, 2400])\nprice = np.array([399900, 329900, 369000])\n\n# size = np.array([2000, 2500, 3000, 3500, 4000])\n# price = np.array([300000, 350000, 400000, 450000, 500000])\n\n# size = np.array([2104, 1600, 2400, 1890])\n# price = np.array([399900, 329900, 369000, 340900])\n\n# Convert numpy arrays to PyTorch tensors\nsize_tensor = torch.from_numpy(size).float().unsqueeze(1)\nprice_tensor = torch.from_numpy(price).float().unsqueeze(1)\n\n# Create a TensorDataset\ndata = TensorDataset(size_tensor, price_tensor)\n\n# Create a DataLoader for training\ntrain_loader = DataLoader(data, batch_size = 1, shuffle = True)\n\nprint(data[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize our data","metadata":{}},{"cell_type":"code","source":"# Create a plot of X against Y\nplt.scatter(size, price)\nplt.axis([1500, 2500, 200000, 500000])\n\n\n# Display the plot\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basics of Deep Learning: Creating our model\n\nThis is a very simple neuron, also known as a perceptron, with 1 weight and 1 bias. This is the building block of all neural networks.","metadata":{}},{"cell_type":"markdown","source":"## Linear Transformation\n\nLinear transformations according to pytorch's doc is: \n\n## y = (n * A^T) + b\n\nwhere,\n* n is our input\n* A^T is the transose of the weight matrix\n* b is the bias\n\nSimilar to y = mx + b, the graph of our function is a line.\n\n![Linear Transformation](https://jalammar.github.io/images/NNs_bias_2.png)\n\n* Source: [A Visual and Interactive Guide to the Basics of Neural Networks](https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/)","metadata":{}},{"cell_type":"code","source":"class Perceptron (nn.Module):\n    \"\"\"\n    Perceptron with linear activation.\n\n    Args:\n      x: Input tensor of shape (batch_size).\n\n    Returns:\n      Output tensor of shape (batch_size, 1).\n    \"\"\"\n    def __init__(self, in_features):\n        super(Perceptron, self).__init__()\n        \n        # Linear combination of weights and input \n        # y = torch.mm(x, w) + b\n        self.linear = nn.Linear(in_features, 1, bias = True)\n\n    def forward(self, x):\n        y = self.linear(x)\n        return y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neuron = Perceptron(1)  # Assuming 1 input feature\nprint(neuron)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define our hyperparameters","metadata":{}},{"cell_type":"markdown","source":"## Optimizer\n\nAn optimizer is the learning function we use to manipulate the weights and bias. Doing so will help us get outputs that are close to the expected output. Visually, this results in a line that is close to our data points. This will also result in our loss function's output approaching 0, which visually would look like a line, straight or curved, getting lower and approaching the x axis itself.\n\nOur optimizer changes our weights and bias through a process called backpropagation. Once we have taken our input and passed it through our linear function described earlier, we find the derivative of that function with respect to the input. We can use then use the derivative as the gradient, and we go the opposite way. \n\nNote: Backpropagation is often discusses with bigger models that have multiple weights and biases (parameters), so terms like chain rule, partial derivatives, and graidents make the most sense in those contexts.  ","metadata":{}},{"cell_type":"markdown","source":"## Loss Function\n\nA loss function is another, separate function that takes in the output of our original function and compares it the expected/correct output. Since it's a function, it too has a graph. We want to get the output of this function as close to 0 as we can. To do this, we use something called an optimizer.","metadata":{}},{"cell_type":"code","source":"def mean_squared_error(output, price):\n    \"\"\"\n    Find the difference of our predicted and actual values,\n    squares it to avoid negative values, and finds the mean \n    of all differences. \n    \n    Args:\n      output: Input tensor of shape (1,).\n      price: Input tensor of shape (1,).\n    \n    Returns:\n      A scalar value representing the mean squared error.\n    \"\"\"\n\n    # compute mean squared error\n    mse = torch.mean((output - price) ** 2)\n    \n    # returns error\n    return mse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = torch.zeros(1)\n\n# Define the learning rate and number of epochs\nlearning_rate = 0.001\nnum_epochs = 100\n\n# Define loss and optimizer\ncriterion = mean_squared_error(output, price) # output = prediction, price = actual\noptimizer = torch.optim.SGD(neuron, lr = learning_rate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(num_epochs):\n    epoch_loss = 0.0  # Track loss for each epoch\n\n    for size, price in train_loader:\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = neuron(size)\n\n        # Loss & Backward pass\n        loss = criterion((outputs, price))\n        loss.backward(retain_graph=True)\n\n        optimizer.step()\n\n        epoch_loss += loss.item()  # Accumulate loss\n\n    # Print loss at the end of each epoch\n    print(f'Epoch [{epoch + 1} / {epochs}] Loss: {epoch_loss / len(train_loader)}')\n\n    # Print weights and biases \n    # Clone and detach for safety\n    weight_copy = neuron.linear.weight.clone().detach()\n    bias_copy = neuron.linear.bias.clone().detach()\n    print(\"Weight:\", weight_copy)\n    print(\"Bias:\", bias_copy)\n\n# Print the final weights and bias\nprint(\"Final Weight:\", weight_copy)\nprint(\"Final Bias:\", bias_copy)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss Function Landscape\n\nVisually, identifying the gradient of the loss function and going the opposite way would look like navigating an invisible, hilly landscape where we can only see the steps we have taken, but we can also see the steepest point in our immediate vicinity using the gradient derived from the parial derivatives and we \"descend\".\n\nWhen visualizing gradient descent in linear regression, you're essentially visualizing the descent on the loss function landscape, not directly on the curve fitting function (y = (n(A^T)) + b) itself.\n\n## Loss Function Landscape:\n\nImagine a 3D space where the x and y axes represent the model's parameters (e.g., slope and intercept for linear regression), and the z-axis represents the loss function value.\n\nThis 3D space is called the loss function landscape. Points with lower loss values are like valleys, and points with higher loss values are like hills or mountains.\n\n## Gradient Descent in this Landscape:\n\nGradient descent works by iteratively adjusting the model's parameters in the direction that minimizes the loss function.\n\nWe calculate the gradient of the loss function at the current parameter values. The gradient points in the direction of steepest descent on the loss function landscape.\n\nBy taking small steps in the negative direction of the gradient (opposite direction of steepest ascent), we move the model's parameters towards lower loss regions in the landscape.\n\n## Visualizing Descent:\n\nIn visualizations, we typically project this 3D landscape onto a 2D plane, often showing the loss value as a color gradient (darker for lower loss, brighter for higher loss).\n\nWe then plot the path of the model's parameters (a series of points) as they move through the landscape during gradient descent iterations. This path represents the model's journey towards finding the minimum loss (often visualized as a valley in the landscape).\n\nWhile you see the line representing the model's fit getting \"closer\" to the data points, you're not directly visualizing movement on that line. You're visualizing the descent on the loss function landscape, which guides the model's parameters to create a better fit.\n\nwe don't know what the landscape look like right? Since it is being \"rendered\" as we calculate the loss value. Are we using the derivatives, or partial derivatives via the chain rule for multiple parameters, as some kind of powerful goggles that can generate the area within our immediate proximity where the gradient is the highest point in this generation\n\nYou're exactly right! The loss function landscape is a helpful conceptualization, but it's not something we can directly \"see\" or fully render beforehand. Here's a more detailed explanation:\n\n## Unknown Landscape:\n\nThe true loss function landscape for a complex model with many parameters is high-dimensional and very difficult to visualize in its entirety. We only have access to the loss value and its derivatives at specific points (parameter values) during training.\n\n## Navigating with Derivatives:\n\nYou're right on the mark with the goggles analogy. We use the derivatives (partial derivatives via the chain rule for multiple parameters) as a powerful tool to navigate this hidden landscape.\n\nThe gradient, calculated using these derivatives, tells us the direction of steepest ascent in the loss function landscape at the current parameter location.\n\nBy taking the negative of the gradient (since we want to minimize the loss), we get the direction of steepest descent.\n\n## Limited View:\n\nHowever, the derivatives only provide local information about the immediate vicinity of the current parameter values. They don't give us a complete picture of the global landscape.\n\n## Optimization Algorithms:\n\nGradient descent algorithms like the one you saw earlier use this local information from derivatives to iteratively update the parameters.\n\nWith each update, the algorithm moves to a new point (parameter values) in the landscape and calculates a new gradient to continue its descent towards a minimum.\n\n## Challenges and Stochasticity:\n\nThe landscape can have many valleys and ridges, making it challenging to find the global minimum.\n\nIn practice, we often aim to find a good local minimum that avoids overfitting.\n\nSome optimization algorithms like stochastic gradient descent (SGD) introduce randomness to help escape local minima and explore the landscape more broadly.","metadata":{}}]}